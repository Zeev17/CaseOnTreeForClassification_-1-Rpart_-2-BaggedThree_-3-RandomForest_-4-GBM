#setwd("C:/Users/Install/Desktop/Tree in R")

########################################################################
#DEfinition bagged tree model
########################################################################
library(ipred)
#number of bagged trees can be specified using the nbagg parameter
#here we will use the default (25)

#If we want to estimate the model's accuracy using the "out-of-bag" (OOB) samples
#we can set the the coob parameter to TRUE

#The OOB samples are the training obsevations that were not selected into the bootstrapped sample (used in training)
#Since these observations were not used in training, we can use them instead to evaluate the accuracy of the model
#done automatically inside the bagging() function

credit <- read.csv("credit.csv", stringsAsFactors = TRUE)
########################################################################
#Split data in 80% 20%
########################################################################
# Total number of rows in the credit data frame
n <- nrow(credit)
# Number of rows for the training set (80% of the dataset)
n_train <- round(0.8 * n) 
# Create a vector of indices which is an 80% random sample
set.seed(123)
train_indices <- sample(1:n, n_train)
# Subset the credit data frame to training indices only
credit_train <- credit[train_indices, ]  
# Exclude the training indices to create the test set
credit_test <- credit[-train_indices, ]

########################################################################
#Train a bagged tree model
########################################################################

# Bagging is a randomized model, so let's set a seed (123) for reproducibility
set.seed(123)

# Train a bagged model
credit_model <- bagging(formula = default ~ ., 
                        data = credit_train,
                        coob = TRUE)

# Print the model
print(credit_model)

########################################################################
#Prediction and confusion matrix
########################################################################
library(caret)
# Generate predicted classes using the model object
class_prediction <- predict(object = credit_model,    
                            newdata = credit_test,  
                            type = "class")  # return classification labels

# Print the predicted classes
print(class_prediction)

# Calculate the confusion matrix for the test set
confusionMatrix(data = class_prediction,       
                reference = credit_test$default)
#Accuracy 0.76

########################################################################
#Predict on a test set and compute AUC
########################################################################
#In binary classification problems, we can predict numeric values instead of class labels
#In fact, class labels are created only after you use the model to predict a raw, numeric, predicted value for a test point.

#The predicted label is generated by applying a threshold to the predicted value, 
#all tests points with predicted value greater than that threshold get a predicted label of "1"
#AUC is a common metric for evaluating the discriminatory ability of a binary classification model.

library(Metrics)
# Generate predictions on the test set
pred <- predict(object = credit_model,
                newdata = credit_test,
                type = "prob")
# pred is a matrix
class(pred)
# Look at the pred format
head(pred)

# Compute the AUC (`actual` must be a binary (or 1/0 numeric) vector)
auc(actual = ifelse(credit_test$default == "yes", 1, 0), 
    predicted = pred[,"yes"])   


########################################################################
#Cross-validate a bagged tree model in caret
########################################################################
# Specify the training configuration
ctrl <- trainControl(method = "cv",     # Cross-validation
                     number = 5,      # 5 folds
                     classProbs = TRUE,                  # For AUC
                     summaryFunction = twoClassSummary)  # For AUC

# Cross validate the credit model using "treebag" method; 
# Track AUC (Area under the ROC curve)
set.seed(1)  # for reproducibility
credit_caret_model <- train(default ~ .,
                            data = credit_train, 
                            method = "treebag",
                            metric = "ROC",
                            trControl = ctrl)

# Look at the model object
print(credit_caret_model)

# Inspect the contents of the model list 
names(credit_caret_model)

# Print the CV AUC
credit_caret_model$results[,"ROC"]
#AUC is 0.72

########################################################################
#Generate predictions from the caret model
########################################################################

# Generate predictions on the test set
pred <- predict(object = credit_caret_model, 
                newdata = credit_test,
                type = "prob")

#saveRDS(pred[,"yes"], file = "bag_preds")

# Compute the AUC (`actual` must be a binary (or 1/0 numeric) vector)
auc(actual = ifelse(credit_test$default == "yes", 1, 0), 
    predicted = pred[,"yes"])
#AUC is 0.77

########################################################################
#Compare test set performance to CV performance
########################################################################
#Lastly, we will print the 5-fold cross-validated estimate of AUC that is stored within the credit_caret_model
#This number will be a more accurate estimate of the true model performance since we have averaged the performance over five models instead of just one.
#When using small data, it's recommended to use cross-validated estimates of performance because they are more stable

#object stores the test set AUC from the model trained using the ipred::bagging() function.
credit_ipred_model_test_auc <- 0.7762389

#object stores the test set AUC from the model trained using the caret::train() function with method = "treebag"
credit_caret_model_test_auc <- 0.76

# Print ipred::bagging test set AUC estimate
print(credit_ipred_model_test_auc)

# Print caret "treebag" test set AUC estimate
print(credit_caret_model_test_auc)

# Compare to caret 5-fold cross-validated AUC
credit_caret_model$results[, "ROC"]

